[{"content":"","date":"1 mayo 2024","externalUrl":null,"permalink":"/es/","section":"Alberto Olvera","summary":"","title":"Alberto Olvera","type":"page"},{"content":" Automatización de la Infraestructura: Proxmox, Ansible y Terraform # Administrar la infraestructura en un homelab puede ser complejo y llevar mucho tiempo. Aquí exploraremos cómo aprovechar las fortalezas de Proxmox, Ansible y Terraform para optimizar el aprovisionamiento y la configuración de la infraestructura en un entorno de laboratorio casero.\n¿Por qué elegir este trio? # Proxmox: Proporciona una potente plataforma de virtualización para administrar máquinas virtuales en tu lab. Ansible: Ofrece un motor de automatización para automatizar tareas en tus máquinas virtuales, independientemente de su ubicación. Terraform: Habilita la Infraestructura como Código (IaC), lo que te permite definir y administrar tu infraestructura utilizando archivos de configuración. Desglose del Proyecto # Aprovisionamiento de Máquinas Virtuales:\nUtilizando el proveedor Terraform de Proxmox para definir configuraciones de VM y LXC (tamaño, almacenamiento, red). Terraform interactuará con la API de Proxmox para crear máquinas virtuales en tu laboratorio. Playbooks de Ansible:\nCrea playbooks de Ansible que se dirijan a tus máquinas virtuales aprovisionadas utilizando archivos de inventario, los cuales están vinculados directamente a las máquinas virtuales Proxmox usando el proveedor Terraform de Ansible. Los playbooks pueden configurar instalaciones de software, administración de usuarios, configuraciones de seguridad y cualquier otra tarea específica de la máquina virtual. Gestión Centralizada:\nEjecuta Terraform y los playbooks de Ansible desde una ubicación central para administrar la infraestructura en tu laboratorio de manera consistente. Los sistemas de control de versiones como Git pueden rastrear los cambios en la infraestructura y permitir reversiones si es necesario. Aprovisionamiento de Proxmox con Terraform # Esta sección detalla cómo aprovechar Terraform para aprovisionar máquinas virtuales y contenedores en un cluster Proxmox. Esta publicación de blog utiliza un repositorio de ejemplo que contiene código Terraform para este propósito.\nRequisitos # Terraform instalado Cluster Proxmox con acceso a la API habilitado Proveedor de Terraform para Proxmox Proveedor de Terraform para Ansible Variables # La configuración de Terraform se basa en varias variables para definir tu entorno:\nproxmox_node: Nombre del nodo Proxmox para desplegar el contenedor. proxmox_api_url: URL del punto final de la API de Proxmox VE. proxmox_api_token_id: ID del token de API con los permisos adecuados. proxmox_api_token_secret: Secreto del token de API asociado con el ID del token. ct_password: Contraseña para la cuenta de usuario sin privilegios. ansible_user: Cuenta de la máquina virtual utilizada por Ansible. ansible_password: Contraseña de la cuenta utilizada por Ansible. ansible_become_password: Contraseña de la cuenta Sudo utilizada por Ansible. Uso # Clonar el Repositorio:\nComienza por clonar el repositorio que contiene el código Terraform para aprovisionar máquinas virtuales y contenedores en tu cluster Proxmox.\nCrear un Usuario de Terraform:\nEn tu cluster Proxmox, crea un usuario de Terraform con los permisos necesarios:\npveum role add TerraformProv -privs \u0026#34;Datastore.AllocateSpace Datastore.Audit Pool.Allocate Sys.Audit Sys.Console Sys.Modify VM.Config.CDROM VM.Config.Cloudinit VM.Config.CPU VM.Config.Disk VM.Config.HWType VM.Config.Memory VM.Config.Network VM.Config.Options VM.Migrate VM.Monitor VM.PowerMgmt SDN.Use\u0026#34; pveum user add terraform-prov@pve --password \u0026lt;password\u0026gt; pveum aclmod / -user terraform-prov@pve -role TerraformProv pveum user token add terraform-prov@pve tftoken Explicación:\nEste script define un rol llamado TerraformProv con los privilegios requeridos para la administración de VM y contenedores. Crea un usuario llamado terraform-prov@pve y le asigna el rol TerraformProv. Se genera un token de API llamado tftoken para el usuario. Recuerda reemplazar \u0026lt;password\u0026gt; con una contraseña segura para el usuario. Configurar las Variables de Terraform:\nCrea un archivo llamado .tfvars en el mismo directorio que el repositorio clonado. Este archivo almacenará tus variables de Terraform.\nActualiza los valores de cada variable según tu entorno:\nproxmox_node: Nombre de tu nodo Proxmox. proxmox_api_url: URL de tu punto final de la API de Proxmox VE (por ejemplo, https://tu-servidor-proxmox:8006/api/2.6/). proxmox_api_token_id: El ID del token de API generado para el usuario de Terraform. proxmox_api_token_secret: El secreto del token de API asociado con el ID. ct_password: Contraseña para la cuenta de usuario sin privilegios dentro del contenedor (si es aplicable). ansible_user: Cuenta de la máquina virtual utilizada por Ansible. ansible_password: Contraseña de la cuenta utilizada por Ansible. ansible_become_password: Contraseña de la cuenta Sudo utilizada por Ansible. Inicializar y Aplicar Terraform:\nNavega al directorio que contiene el repositorio clonado y tu archivo .tfvars.\nEjecuta terraform init para inicializar Terraform y descargar los complementos de proveedor necesarios. Ejecuta terraform plan para obtener una vista previa de los cambios que se realizarán en tu cluster Proxmox según tu configuración de Terraform. Una vez que estés satisfecho con el plan, ejecuta terraform apply para aplicar la configuración y aprovisionar las máquinas virtuales o contenedores en tu cluster Proxmox. Al aprovechar Terraform con Proxmox, puedes automatizar las implementaciones de VM y contenedores, lo que agiliza tu proceso de administración de infraestructura. Recuerda consultar la documentación oficial de Terraform y Proxmox para obtener mejores prácticas y escenarios de uso avanzado.\n","date":"1 mayo 2024","externalUrl":null,"permalink":"/es/posts/20240501-ansible-tfprovider/","section":"Posts","summary":"Esta guía explora cómo usar Proxmox, Ansible y Terraform juntos para automatizar el aprovisionamiento de infraestructura en un homelab.","title":"Configuracion de tu HomeLab con Proxmox, Ansible y Terraform\"","type":"posts"},{"content":"","date":"1 mayo 2024","externalUrl":null,"permalink":"/es/tags/homelab/","section":"Tags","summary":"","title":"Homelab","type":"tags"},{"content":"","date":"mayo 1 2024","externalUrl":null,"permalink":"/series/homelab-automated-setup/","section":"Series","summary":"","title":"Homelab Automated Setup","type":"series"},{"content":"","date":"mayo 1 2024","externalUrl":null,"permalink":"/tags/homelab-management/","section":"Tags","summary":"","title":"Homelab Management","type":"tags"},{"content":"","date":"1 mayo 2024","externalUrl":null,"permalink":"/es/series/homelab-setup-automatico/","section":"Series","summary":"","title":"Homelab Setup Automatico","type":"series"},{"content":"","date":"1 mayo 2024","externalUrl":null,"permalink":"/es/tags/infrastructure-as-code/","section":"Tags","summary":"","title":"Infrastructure as Code","type":"tags"},{"content":"","date":"1 mayo 2024","externalUrl":null,"permalink":"/es/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"","date":"1 mayo 2024","externalUrl":null,"permalink":"/es/series/","section":"Series","summary":"","title":"Series","type":"series"},{"content":"","date":"1 mayo 2024","externalUrl":null,"permalink":"/es/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"14 abril 2024","externalUrl":null,"permalink":"/es/tags/home-lab/","section":"Tags","summary":"","title":"Home Lab","type":"tags"},{"content":" Monitoreando tu cluster Proxmox con Prometheus y Grafana # Este post te guiará a través de la configuración del monitoreo de Proxmox utilizando Prometheus y Grafana. Al implementar esta solución, obtendrás información valiosa sobre el estado y el rendimiento de tu entorno Proxmox, lo que te permitirá identificar posibles problemas antes de que se intensifiquen y optimizar la asignación de recursos para tus máquinas virtuales y contenedores.\n¿Quién debería seguir esta guía?\nEsta guía es ideal para aquellos que ya están familiarizados con Proxmox y desean agregar una capa de monitoreo a su configuración. Será útil tener una comprensión básica de los conceptos de Linux y familiaridad con la línea de comandos.\nLa configuración # Configuraré mi monitoreo de manera que no tenga que instalar nada en mis nodos Proxmox. En su lugar, instalaré la pila de monitoreo completa en una de las máquinas virtuales que se ejecutan en mi cluster.\nAl igual que en el siguiente diagrama, tendré un servidor AlmaLinux ejecutándose en mi cluster que alojará lo siguiente:\nServidor Prometheus Grafana Exportador Prometheus VE flowchart LR; PV1[PVE1]--\u003ePE[PVE Exporter]; subgraph ide1 [AlmaLinux VM] PE[PVE Exporter]--\u003ePS[Prometheus Server] --\u003e G[Grafana] end PV2[PVE2]--\u003ePE PV3[PVE3]--\u003ePE; PV4[PVE4]--\u003ePE; style ide1 fill:#888 stroke:#000,stroke-width:4px,stroke-dasharray: 5 5 Consideraciones de seguridad:\nSi bien la guía muestra el proceso de configuración, es importante tener en cuenta que el ejemplo utiliza una contraseña débil para Prometheus.\nEn un entorno real, siempre elige una contraseña segura y única para proteger tu configuración de monitoreo. Introducción a las herramientas: # Prometheus: # Un sistema de monitoreo de código abierto que actúa como un recolector central, extrayendo métricas de diversas fuentes como Proxmox VE a intervalos regulares y almacenándolas en una base de datos de series temporales.\nGrafana: # Una plataforma de código abierto para visualizar datos. Te permite crear paneles interactivos que muestran las métricas recopiladas por Prometheus, lo que facilita la comprensión del uso de recursos, identificar tendencias y solucionar problemas.\nCon una combinación de estas dos herramientas en tu cluster Proxmox puedes obtener los siguientes beneficios:\nVisibilidad mejorada: Obtén información en tiempo real sobre el rendimiento de Proxmox VE, incluido el uso de CPU, memoria, almacenamiento y red. Detección proactiva de problemas: identifica posibles problemas antes de que se intensifiquen, lo que te permite tomar medidas preventivas. Gestión de recursos mejorada: optimiza la asignación de recursos para tus máquinas virtuales y contenedores en función de los datos de uso real. Toma de decisiones informada: obtén información basada en datos para tomar decisiones informadas sobre cómo escalar tu infraestructura Proxmox VE. Configuración del monitoreo # Prometheus # Instalación # Hay muchas opciones para instalar, usaré uno de los binarios precompilados oficiales que se proporcionan en su página de descargas: https://prometheus.io/download/.\nAsí que descargaré su archivo tar y lo extraeré con el siguiente comando.\ntar xfvz prometheus.tar.gz -C prometheus Primero, agrega un nuevo usuario específico para el uso de Prometheus\nsudo useradd --no-create-home --shell /bin/false prometheus Crea los directorios necesarios para Prometheus y cambia la propiedad de ellos.\nsudo mkdir /etc/prometheus sudo mkdir /var/lib/prometheus sudo chown prometheus:prometheus /etc/prometheus sudo chown prometheus:prometheus /var/lib/prometheus Comienza copiando las herramientas esenciales de Prometheus (prometheus y promtool) a sus ubicaciones designadas:\ncp prometheus/prometheus /usr/local/bin/ cp prometheus/promtool /usr/local/bin/ Asegúrate de que el usuario de Prometheus sea el propietario de estos binarios para una ejecución adecuada:\nchown prometheus:prometheus /usr/local/bin/prometheus chown prometheus:prometheus /usr/local/bin/promtool Configuración # Utiliza un editor de texto (en el caso de AlmaLinux, vi viene preinstalado) para crear el archivo de configuración de Prometheus:\nvi /etc/prometheus/prometheus.yml Agrega la configuración:\nglobal: scrape_interval: 10s scrape_configs: - job_name: \u0026#39;prometheus\u0026#39; scrape_interval: 5s static_configs: - targets: [\u0026#39;localhost:9090\u0026#39;] - job_name: \u0026#39;pve\u0026#39; static_configs: - targets: - \u0026lt;IP of node 1\u0026gt; # pve1 - \u0026lt;IP of node 2\u0026gt; # pve2 metrics_path: /pve params: module: [default] cluster: [\u0026#39;1\u0026#39;] node: [\u0026#39;1\u0026#39;] relabel_configs: - source_labels: [__address__] target_label: __param_target - source_labels: [__param_target] target_label: instance - target_label: __address__ replacement: \u0026lt;IP from the VM where the exporter is installed\u0026gt;:9221 En este archivo, definimos:\nEl intervalo de raspado: la frecuencia con la que Prometheus recopila datos. Un trabajo llamado \u0026lsquo;prometheus\u0026rsquo; para raspar las propias métricas de Prometheus. Un trabajo llamado \u0026lsquo;pve\u0026rsquo; para raspar las métricas de nuestros nodos Proxmox VE. La ruta a la ruta de la API del exportador PVE. Parámetros para especificar el clúster y el nodo a los que se hace referencia en las métricas. Etiquetas de re-etiquetado para transformar las etiquetas de origen en las etiquetas deseadas. Guarda y ajusta la propiedad: Una vez que hayas agregado la configuración, guarda el archivo y asegúrate de que el usuario de Prometheus sea el propietario:\nsudo chown prometheus:prometheus /etc/prometheus/prometheus.yml Configurar Prometheus como servicio de Linux # Dado que quiero monitorear mi cluster en cualquier momento, configuraré el servidor Prometheus como un servicio de Linux usando Systemd:\nAgrega esto al archivo /etc/systemd/system/prometheus.service:\n[Unit] Description=Prometheus Wants=network-online.target After=network-online.target [Service] User=prometheus Group=prometheus Type=simple ExecStart=/usr/local/bin/prometheus \\ --config.file /etc/prometheus/prometheus.yml \\ --storage.tsdb.path /var/lib/prometheus/ \\ --web.console.templates=/etc/prometheus/consoles \\ --web.console.libraries=/etc/prometheus/console_libraries [Install] WantedBy=multi-user.target Aplicar cambios y verificar el estado:\nRecarga systemd: Después de guardar la configuración de Prometheus, informa a systemd sobre los cambios usando:\nsudo systemctl daemon-reload Inicia Prometheus: Finalmente, inicia el servicio Prometheus:\nsudo systemctl start prometheus sudo systemctl enable prometheus Verificar estado: Para confirmar si Prometheus se está ejecutando correctamente, verifica su estado con:\nsudo systemctl status prometheus Para ahora, deberías tener Prometheus ejecutándose en tu máquina virtual y accesible desde la interfaz web en el puerto 9090.\nGrafana # Instalación # En el caso de la instalación de Grafana, usaré el administrador de paquetes predeterminado para instalar la versión OSS de Grafana:\nsudo dnf install grafana Una vez finalizada la instalación, inicia y habilita el servidor Grafana con estos comandos:\nsudo systemctl start grafana-server sudo systemctl enable grafana-server Acceso a la interfaz web: Con Grafana en ejecución, puedes acceder a su interfaz web en http://\u0026lt;IP de la Máquina virtual\u0026gt;:3000 en tu navegador web.\nInicio de sesión inicial: Las credenciales predeterminadas son nombre de usuario: \u0026lsquo;admin\u0026rsquo; y contraseña: \u0026lsquo;admin\u0026rsquo;. Se te pedirá que cambies la contraseña al iniciar sesión por primera vez por razones de seguridad.\nConfiguración avanzada (opcional): Para obtener más configuración (por ejemplo, alertas por correo electrónico o cambios de puerto), edita el archivo /etc/grafana/grafana.ini utilizando cualquier editor de texto:\nsudo vi /etc/grafana/grafana.ini Realiza los ajustes necesarios dentro del archivo y guarda los cambios.\nUsaremos Prometheus-pve-exporter: https://github.com/prometheus-pve/prometheus-pve-exporter para enviar las métricas de nuestros clusters a nuestro servidor Prometheus y desde allí a Grafana.\nInstalación # Asegúrate de que venv esté instalado (es decir, apt install python3-venv), luego prepara un nuevo entorno para el Exportador PVE:\npython3 -m venv /opt/prometheus-pve-exporter Instala el Exportador PVE en el nuevo entorno:\n/opt/prometheus-pve-exporter/bin/pip install prometheus-pve-exporter Configuración # Antes de ejecutar el exportador, debemos crear un usuario Proxmox que el exportador utilizará para raspar las métricas. Crea un nuevo usuario en la sección Datacenter -\u0026gt; Usuarios. Completa el nombre de usuario, establece el dominio en Autenticación Proxmox VE y dale tu contraseña. Crea el usuario promexporter en tu cluster Proxmox Regresa a los Permisos. Establece la ruta a \u0026lsquo;/\u0026rsquo;. Selecciona tu usuario. Dale el rol Auditor PVE. Agrega el rol Auditor PVE al nuevo usuario A continuación, crea un archivo de configuración para el exportador: /etc/prometheus/pve.yml En este archivo, debes especificar los detalles del usuario del usuario promexporter que acabamos de crear y agregaremos una bandera para omitir la verificación del cluster Proxmox:\ndefault: user: promexporter@pve password: supersecretpassword verify_ssl: false Exportador PVE como servicio de Linux # Dado que quiero monitorear mi cluster en cualquier momento, configuraré el Exportador PVE como un servicio de Linux usando Systemd:\nAgrega esto al archivo /etc/systemd/system/prometheus-pve-exporter.service:\n[Unit] Description=Prometheus exporter for Proxmox VE Documentation=https://github.com/znerol/prometheus-pve-exporter [Service] Restart=always User=prometheus ExecStart=/opt/prometheus-pve-exporter/bin/pve_exporter /etc/prometheus/pve.yml [Install] WantedBy=multi-user.target Aplicar cambios y verificar el estado:\nRecarga systemd: Después de guardar la configuración del exportador, informa a systemd sobre los cambios usando:\nsudo systemctl daemon-reload Inicia el servicio: Finalmente, inicia el servicio de exportador PVE:\nsudo systemctl start prometheus-pve-exporter sudo systemctl enable prometheus-pve-exporter Verificar estado: Para confirmar si el Exportador se está ejecutando correctamente, verifica su estado con:\nsudo systemctl status prometheus-pve-exporter Para ahora, deberías tener el exportador ejecutándose en tu máquina virtual y sus métricas accesibles desde la interfaz web en el puerto 9221.\nPuedes acceder a las métricas con curl:\nAsociando Prometheus con el exportador PVE # Ahora, necesitamos configurar el servidor Prometheus para que recopile las métricas expuestas por el Exportador PVE de Proxmox. Para hacerlo, debemos editar el archivo de configuración de Prometheus /etc/prometheus/prometheus.yml:\nglobal: scrape_interval: 10s scrape_configs: - job_name: \u0026#39;prometheus\u0026#39; scrape_interval: 5s static_configs: - targets: [\u0026#39;localhost:9090\u0026#39;] - job_name: \u0026#39;pve\u0026#39; static_configs: - targets: - \u0026lt;IP of node 1\u0026gt; # pve1 - \u0026lt;IP of node 2\u0026gt; # pve2 metrics_path: /pve params: module: [default] cluster: [\u0026#39;1\u0026#39;] node: [\u0026#39;1\u0026#39;] relabel_configs: - source_labels: [__address__] target_label: __param_target - source_labels: [__param_target] target_label: instance - target_label: __address replacement: \u0026lt;IP de la máquina donde esta el exportador\u0026gt;:9221 En este archivo:\nDefinimos un nuevo trabajo llamado \u0026lsquo;pve\u0026rsquo; para raspar las métricas de nuestros nodos Proxmox VE. Especificamos la ruta a la ruta de la API del exportador PVE. Agregamos parámetros para especificar el clúster y el nodo a los que se hace referencia en las métricas. Configuramos etiquetas de re-etiquetado para transformar las etiquetas de origen en las etiquetas deseadas. Reemplazamos la etiqueta __address__ original con la dirección IP de la máquina virtual donde se está ejecutando el exportador. Guarda y ajusta la propiedad: Una vez que hayas agregado la configuración, guarda el archivo y asegúrate de que el usuario de Prometheus sea el propietario:\nsudo chown prometheus:prometheus /etc/prometheus/prometheus.yml Aplicar cambios:\nRecarga systemd para que reconozca los cambios en el archivo de configuración de Prometheus:\nsudo systemctl daemon-reload Para ahora, deberías tener las métricas del cluster Proxmox accesibles desde tu navegador:\nVisualización de métricas de Proxmox desde Grafana # Una vez que hayas configurado Prometheus y Grafana, el siguiente paso es conectarlos para que Grafana pueda visualizar las métricas recopiladas por Prometheus. Así es como se logra:\nAgrega Prometheus como una fuente de datos en Grafana:\nAbre la interfaz web de Grafana en tu navegador. Inicia sesión con tus credenciales. En la barra lateral izquierda, haz clic en el icono de engranaje de configuración y selecciona \u0026ldquo;Fuentes de datos\u0026rdquo;. Haz clic en \u0026ldquo;Agregar fuente de datos\u0026rdquo;. Elige \u0026ldquo;Prometheus\u0026rdquo; como tipo. En el campo \u0026ldquo;URL\u0026rdquo;, ingresa la dirección de tu servidor Prometheus. Si Prometheus se está ejecutando en la misma máquina que Grafana, puedes usar http://\u0026lt;Prometheus Server IP\u0026gt;:9090. Haz clic en \u0026ldquo;Guardar y probar\u0026rdquo; para verificar la conexión. Si es exitosa, verás un mensaje que confirma la conectividad. Explora y visualiza las métricas:\nLa forma más rápida de utilizar las métricas es exportar un excelente panel: https://grafana.com/grafana/dashboards/10347-proxmox-via-prometheus/ que está disponible al público.\nEste panel se puede importar a nuestro servidor Grafana y vendrá preconfigurado con gráficos y tablas útiles de nuestro cluster, que se verá así:\nAccesing the Proxmox dashboard on Grafana: grafana_working.png\nAl explorar este panel, puedes obtener información valiosa sobre el estado y el rendimiento de tu entorno Proxmox. Puedes ver métricas como el uso de CPU, memoria, almacenamiento y red para cada nodo en tu cluster. También puedes ver gráficos que muestran tendencias en el tiempo, lo que te permite identificar posibles problemas antes de que se intensifiquen.\n¡Felicidades! Ahora deberías poder monitorear tu cluster Proxmox con Prometheus y Grafana. Esta configuración te proporcionará información valiosa que te ayudará a mantener tu cluster en funcionamiento sin problemas y optimizar el rendimiento.\n","date":"14 abril 2024","externalUrl":null,"permalink":"/es/posts/20240414-prometheus-proxmox/","section":"Posts","summary":"Vamos a hablar sobre el monitoreo de un cluster de Proxmox","title":"Monitoreando tu cluster de Proxmox con Prometheus y Grafana","type":"posts"},{"content":"","date":"14 abril 2024","externalUrl":null,"permalink":"/es/tags/proxmox/","section":"Tags","summary":"","title":"Proxmox","type":"tags"},{"content":"","date":"febrero 4 2024","externalUrl":null,"permalink":"/series/almalinux-administration-basics/","section":"Series","summary":"","title":"AlmaLinux Administration Basics","type":"series"},{"content":" Administración básica de AlmaLinux - Firewalld # En esta entrada compartiré una pequeña guía para administrar las reglas del firewall en un entorno AlmaLinux. Como se vio en entradas anteriores, esta serie cubre aspectos que tuve que aprender al ejecutar mi propio Laboratorio Casero en Proxmox.\nFirewalld, el firewall predeterminado en distribuciones basadas en RHEL, fue diseñado como un reemplazo para iptables introducido en 2011.\nEn esencia, firewalld actúa como un guardián de seguridad, controlando el tráfico de red entrante y saliente.\nSi bien viene prehabilitado con una configuración predeterminada segura, es posible que deba abrir puertos específicos para que los servicios esenciales funcionen correctamente.\nPor ejemplo, al encontrar problemas con la exportación de métricas de nodos en mis máquinas virtuales, revisé mis configuraciones de Proxmox y de red, solo para descubrir que el tráfico estaba siendo bloqueado por la propia máquina virtual.\nSi te encuentras en una situación similar, esta guía te ayudará con lo siguiente:\nPermitir puertos o servicios a través del firewall: Otorgar acceso a las conexiones entrantes para los servicios elegidos. Aplicar reglas de firewall: Activar los cambios realizados en las configuraciones del firewall. Verificar puertos y servicios abiertos: Mantenerse al tanto de los puertos y servicios actualmente accesibles. Administrar puertos abiertos: Revocar el acceso cuando ya no se requiera un servicio. Puertos y zonas del Firewall # Firewalld utiliza zonas para categorizar las interfaces de red y gestionar el flujo de tráfico en consecuencia. La interfaz de red de tu laboratorio casero probablemente pertenece a la zona \u0026ldquo;pública\u0026rdquo;, que maneja el tráfico proveniente de internet.\nGeneralmente, la regla predeterminada de un firewall es denegar todo y solo permitir el paso de excepciones específicas para los servicios necesarios. Puedes agregar reglas a esta zona para controlar el tráfico entrante desde internet. Existen dos métodos principales para abrir puertos:\nPor servicio: Este es el enfoque preferido, ya que abre automáticamente el número de puerto relevante asociado a un servicio. Por ejemplo, el siguiente comando permite el tráfico HTTP en el puerto 80. bash firewall-cmd --zone=public --add-service=http --permanent Por número de puerto: Utiliza este método si no hay un servicio correspondiente para el puerto que deseas abrir. El siguiente comando abre el puerto 8080 para conexiones TCP: bash firewall-cmd --zone=public --add-port=8080/tcp --permanent Comandos esenciales de administración de Firewall # Listar servicios y puertos abiertos: Mostrar servicios activos con puertos abiertos bash firewall-cmd --zone=public --list-services Mostrar puertos abiertos independientemente del servicio asociado bash firewall-cmd --zone=public --list-ports Recargar Firewall: Esto activará cualquier cambio permanente realizado en las reglas del firewall bash firewall-cmd --reload Ver todas las reglas del firewall: Proporciona una vista completa de la configuración de tu firewall: bash firewall-cmd --list-all Cerrar un puerto: Elimina la regla HTTPS del firewall bash firewall-cmd --zone=public --permanent --remove-service=HTTPS Puertos comunes y comandos de Firewall para servicios de laboratorio casero # Estos son algunos comandos útiles para abrir puertos para servicios esenciales que podrías usar en tu entorno de laboratorio casero:\n# Permitir HTTP a través del firewall firewall-cmd --zone=public --add-service=http --permanent # Permitir HTTPS a través del firewall firewall-cmd --zone=public --add-service=https --permanent # Permitir MySQL a través del firewall firewall-cmd --zone=public --add-service=mysql --permanent # Permitir SSH a través del firewall (suponiendo que no esté ya abierto) firewall-cmd --zone=public --add-service=ssh --permanent # Permitir DNS a través del firewall firewall-cmd --zone=public --add-service=dns --permanent # Permitir PostgreSQL a través del firewall firewall-cmd --zone=public --add-service=postgresql --permanent # Permitir telnet a través del firewall firewall-cmd --zone=public --add-service=telnet --permanent Consideraciones de seguridad al abrir puertos # La seguridad siempre debe ser tu prioridad al administrar tu firewall. Solo abre puertos para los servicios que realmente necesitas y utilizas activamente en tu laboratorio casero. Aquí hay algunas prácticas recomendadas de seguridad adicionales a tener en cuenta:\nMinimizar puertos expuestos: Abre solo los puertos específicos necesarios para que un servicio funcione. Evita abrir rangos completos de puertos. Contraseñas seguras: Utiliza contraseñas seguras para todos los servicios que requieren autenticación, especialmente para los servicios accesibles de forma remota. Mantén el software actualizado: Actualiza periódicamente tu sistema AlmaLinux y las aplicaciones para abordar las vulnerabilidades de seguridad. Monitoriza los registros del firewall: Revisa periódicamente los registros de tu firewall para detectar actividades sospechosas que puedan indicar intentos de acceso no autorizado. Siguiendo estos pasos y comprendiendo las reglas del firewall, puedes administrar de manera efectiva el tráfico entrante en tu laboratorio casero de AlmaLinux.\n","date":"1 febrero 2024","externalUrl":null,"permalink":"/es/posts/20240203-almalinux-3/","section":"Posts","summary":"Conceptos generales para manejar puertos en AlmaLinux","title":"Administración básica de AlmaLinux - Firewalld","type":"posts"},{"content":" ¡Bienvenido a Alma Linux para tu homelab! # ¡Bienvenidos a la primera entrega de nuestra serie sobre cómo ejecutar Alma Linux para las necesidades de servidores en un homelab! Tanto si es un usuario experimentado de Linux como si acaba de comenzar su viaje, un laboratorio doméstico es una manera fantástica de experimentar, aprender nuevas habilidades y alojar sus propios servicios personales. Alma Linux, una bifurcación estable y impulsada por la comunidad de Red Hat Enterprise Linux (RHEL), proporciona una base sólida para construir su entorno de laboratorio doméstico.\n¿Por qué Alma Linux? # Existen varias razones por las que Alma Linux es una excelente opción para laboratorios domésticos:\nEstabilidad: Basado en RHEL, Alma Linux hereda su reconocida estabilidad y su enfoque en el soporte a largo plazo. Esto garantiza que sus servidores funcionen sin problemas y reciban actualizaciones de seguridad durante un período prolongado. Familiaridad: Si planea obtener certificaciones de Red Hat o trabajar en entornos RHEL, Alma Linux ofrece una experiencia familiar que se traduce directamente a esos entornos. Impulsado por la comunidad: Respaldado por una comunidad sólida, Alma Linux ofrece amplios recursos y soporte para ayudarlo a navegar cualquier desafío. Instalación con Proxmox # Como estoy utilizando un cluster Proxmox, cubriré su instalación en una configuración similar a la mía.\nDescargue la versión deseada de Alma Linux, descargué su ISO desde su sitio oficial de descargas: https://almalinux.org/get-almalinux/#ISO_Images. Dentro de la interfaz web de proxmox, cree una nueva máquina virtual. Asigne los núcleos de CPU, memoria y recursos de almacenamiento deseados. Al iniciar la nueva máquina virtual, Alma Linux lo guiará a través de su instalación en una GUI agradable, aquí puede seleccionar el idioma de la instalación y configuraciones como la contraseña root. Durante la instalación de Alma Linux, configure ajustes como el idioma y el cifrado, luego elija software adicional según su entorno base preferido. En esta guía, hemos elegido la selección Servidor. Siéntase libre de seleccionar su entorno preferido y cualquier componente adicional del panel derecho. Una vez que esté satisfecho con sus selecciones, presione el botón ‘Listo’ para volver. Fundamentos básicos de administración # Una vez que tenga Alma Linux instalado, exploremos algunas tareas fundamentales de administración:\nInterfaz de línea de comandos (CLI): La CLI, también conocida como terminal, es su herramienta principal para interactuar con Alma Linux. Familiarícese con los comandos básicos de navegación como cd (cambiar directorio), ls (enumerar el contenido del directorio) y man (acceder a las páginas del manual de los comandos). Gestión de paquetes: Alma Linux utiliza el gestor de paquetes RPM (dnf). Aprenda a instalar, actualizar y eliminar paquetes usando comandos como dnf install \u0026lt;nombre_del_paquete\u0026gt;, dnf update y dnf remove \u0026lt;nombre_del_paquete\u0026gt;. Gestión de usuarios: Cree y administre cuentas de usuario para acceder a su servidor. Utilice los comandos useradd, passwd y userdel para agregar, establecer contraseñas y eliminar usuarios, respectivamente. Recuerde, la cuenta de usuario root es poderosa, así que tenga cuidado al usarla. Gestión de firewalls: El firewall controla el tráfico de red entrante y saliente. Herramientas como firewall-cmd le permiten configurar reglas de firewall para proteger su servidor. Recursos de aprendizaje # Esto es solo una muestra del apasionante mundo de la administración de Alma Linux. Aquí hay algunos recursos para profundizar su conocimiento:\nDocumentación de Alma Linux: https://wiki.almalinux.org/ Guía de administración del sistema de Red Hat: [invalid URL removed] (Si bien no es específica de Alma Linux, ofrece información valiosa sobre la administración de RHEL) Tutoriales en línea: Numerosos tutoriales y cursos en línea se adaptan a todos los niveles de experiencia. Proximamente # En la próxima parte de nuestra serie, analizaremos aplicaciones de servidor específicas que puede implementar en su laboratorio doméstico Alma Linux, junto con detalles de configuración y administración. ¡Esté atento para explorar el potencial de su entorno de laboratorio doméstico!\n","date":"1 febrero 2024","externalUrl":null,"permalink":"/es/posts/20240201-almalinux-1/","section":"Posts","summary":"Explorando AlmaLinux como una gran opción para tu homelab","title":"Administración básica de AlmaLinux - Instalación","type":"posts"},{"content":" Otorgando privilegios Sudo en AlmaLinux 9.2 # Esta guía te lleva paso a paso por el proceso de agregar un usuario con privilegios administrativos en AlmaLinux 9.2.\nUsuarios sin Sudo: # Para usuarios que no necesitan privilegios administrativos, simplemente sigue los pasos 1 y 2 a continuación. Estos usuarios tendrán acceso básico al sistema pero no podrán ejecutar comandos con sudo.\n¿Por qué usuarios Sudo? # Sudo permite a usuarios autorizados ejecutar comandos con permisos elevados, lo cual es crucial para administrar tu servidor de manera efectiva.\nPasos: # Crea un nuevo usuario: Abre una terminal y ejecuta:\nsudo useradd miusuario Reemplaza \u0026ldquo;miusuario\u0026rdquo; con el nombre de usuario deseado.\nConfigura una contraseña segura: Usa el comando passwd seguido del nombre de usuario:\npasswd miusuario Ingresa y confirma una contraseña segura para el usuario. Aquí hay algunas prácticas para contraseñas seguras:\nLongitud: Usa una contraseña de al menos 12 caracteres. Complejidad: Combina letras mayúsculas y minúsculas, números y símbolos. Unicidad: Evita usar la misma contraseña para varias cuentas. Gestores de contraseñas: Considera usar un gestor de contraseñas para generar y almacenar contraseñas seguras y únicas para todas tus cuentas. Otorga acceso Sudo: Linux usa grupos para administrar permisos. El grupo \u0026ldquo;wheel\u0026rdquo; tiene acceso sudo de manera predeterminada. Agreguemos \u0026ldquo;miusuario\u0026rdquo; al grupo \u0026ldquo;wheel\u0026rdquo;:\nsudo usermod -aG wheel miusuario Verifica el acceso Sudo (Opcional): Cambia al nuevo usuario:\nsu - miusuario Intenta ejecutar un comando con sudo:\nsudo ls /root Si te solicita la contraseña del usuario y el comando se ejecuta, entonces se ha otorgado el acceso sudo.\nCuentas de servicio vs. Cuentas de usuario # Hasta ahora, hemos hablado de cuentas de usuario, que son para usuarios humanos que inician sesión e interactúan con el sistema. Existe otro tipo de cuenta: la cuenta de servicio.\nCuentas de servicio: # Estas cuentas son utilizadas por programas o servicios que se ejecutan en tu sistema. Proporcionan una forma segura para que estos programas accedan a recursos sin requerir intervención humana o un inicio de sesión de usuario tradicional. A menudo, a las cuentas de servicio se les asignan permisos específicos, lo que les permite realizar tareas limitadas.\nCuentas de usuario vs. Cuentas de servicio: # La diferencia clave es que las cuentas de usuario son para usuarios humanos, mientras que las cuentas de servicio son para tareas automatizadas. Además, las cuentas de servicio a menudo no tienen un shell de inicio de sesión como los usuarios, en algunas distribuciones tienen /usr/sbin/nologin como shell de inicio de sesión.\nLas cuentas de usuario suelen tener más privilegios y requieren una contraseña para iniciar sesión, mientras que las cuentas de servicio están diseñadas para un acceso programático seguro con permisos limitados.\n¡La seguridad es primero! # Aquí hay algunas prácticas de seguridad clave que debes seguir al administrar usuarios y permisos en tu servidor AlmaLinux:\nPrincipio de privilegio mínimo: Otorga a los usuarios solo los permisos mínimos que necesitan para realizar sus tareas. Esto minimiza el daño si una cuenta de usuario se ve comprometida. Políticas de contraseñas seguras: Implementa requisitos de contraseñas seguras como se mencionó anteriormente. Considera usar un gestor de contraseñas y evita compartir contraseñas. Deshabilita el inicio de sesión root: Para mayor seguridad, deshabilita el inicio de sesión root directo vía SSH. Usa sudo para tareas administrativas cuando sea necesario. Actualizaciones periódicas: Mantén el software y los paquetes de tu sistema actualizados para abordar las vulnerabilidades de seguridad. Monitorea la actividad del sistema: Revisa regularmente los registros del sistema en busca de actividades sospechosas. Al seguir estas prácticas recomendadas de seguridad, puedes minimizar el riesgo de acceso no autorizado y mantener tu servidor AlmaLinux seguro.\nAhora tienes un usuario sudo dedicado para administrar tu servidor AlmaLinux, usuarios no privilegiados separados para las tareas diarias y una comprensión de las cuentas de servicio para procesos automatizados.\nRecuerda, la administración responsable de permisos y las prácticas de seguridad sólidas son clave para mantener un sistema seguro y estable. ","date":"1 febrero 2024","externalUrl":null,"permalink":"/es/posts/20240202-almalinux-2/","section":"Posts","summary":"Conceptos generales para manejar usuarios en AlmaLinux","title":"Administración básica de AlmaLinux - Usuarios","type":"posts"},{"content":"","date":"1 febrero 2024","externalUrl":null,"permalink":"/es/series/administraci%C3%B3n-de-almalinux/","section":"Series","summary":"","title":"Administración De AlmaLinux","type":"series"},{"content":"","date":"1 febrero 2024","externalUrl":null,"permalink":"/es/tags/cli/","section":"Tags","summary":"","title":"CLI","type":"tags"},{"content":"","date":"1 febrero 2024","externalUrl":null,"permalink":"/es/tags/linux-admin/","section":"Tags","summary":"","title":"Linux Admin","type":"tags"},{"content":"","date":"14 mayo 2023","externalUrl":null,"permalink":"/es/tags/azure/","section":"Tags","summary":"","title":"Azure","type":"tags"},{"content":"","date":"14 mayo 2023","externalUrl":null,"permalink":"/es/tags/containers/","section":"Tags","summary":"","title":"Containers","type":"tags"},{"content":"En el mundo de la computación en la nube, nos esforzamos constantemente por lograr una implementación de aplicaciones ágil y eficiente. Las máquinas virtuales (VM) han sido durante mucho tiempo el pilar, pero pueden ser engorrosas. Llegan los contenedores: una alternativa más liviana que agiliza la entrega de aplicaciones.\nEsta publicación de blog analiza los fundamentos de la contenedorización, explorando sus beneficios y cómo se integra con los servicios de Azure como Azure Container Registry (ACR) y Azure Container Instances (ACI).\nMáquinas virtuales vs. Contenedores\nImagine las máquinas virtuales como computadoras autónomas que se ejecutan dentro de una máquina física. Cada VM tiene su propio sistema operativo (SO), consumiendo recursos incluso cuando las aplicaciones están inactivas. Esto puede generar una sobrecarga de mantenimiento e implementaciones lentas.\nLos contenedores, por otro lado, comparten el sistema operativo de la máquina host. Empaquetan una aplicación con todas sus dependencias en una sola unidad, haciéndolas portátiles y eficientes. Esto se traduce en implementaciones más rápidas y una huella de menor tamaño.\nBeneficios de los Contenedores\nPortabilidad: Los contenedores se ejecutan sin problemas en diferentes entornos, ya sea localmente, en la nube o en una computadora portátil. Escalabilidad: Escalar aplicaciones hacia arriba o hacia abajo fácilmente agregando o eliminando contenedores. Agilidad: Implementaciones y reversiones más rápidas debido a la naturaleza liviana de los contenedores. Eficiencia de recursos: Los contenedores comparten el sistema operativo del host, minimizando el consumo de recursos. Construyendo y ejecutando contenedores con Docker\nDocker es una herramienta popular para construir, administrar y ejecutar contenedores. Un Dockerfile especifica las instrucciones para crear una imagen de contenedor, esencialmente un modelo para su aplicación.\nAquí hay un desglose simplificado de la estructura de un Dockerfile:\nImagen base: Defina la imagen del sistema operativo base usando la instrucción FROM. Variables de entorno: Configure variables de entorno específicas para su aplicación. Directorio de trabajo: Cree un directorio para su aplicación usando RUN mkdir y configúrelo como el directorio de trabajo con WORKDIR. Binarios de la aplicación: Copie los binarios de la aplicación en el contenedor usando COPY. Scripts: Copie y ejecute cualquier script necesario usando RUN y especificando el entorno del shell. Puertos expuestos: Exponer el puerto de la aplicación usando el comando EXPOSE. Punto de entrada: Defina el comando de inicio usando la instrucción ENTRYPOINT. Una vez creado el Dockerfile, use el comando docker build para construir la imagen del contenedor.\nAzure Container Registry (ACR)\nACR es un servicio de registro de Docker administrado que simplifica el almacenamiento y la administración de imágenes de contenedor. Se integra perfectamente con su pipeline de CI/CD, automatizando el proceso de compilación, prueba y envío de imágenes de contenedor.\nACR usa Azure Active Directory (AAD) para la autenticación, lo que garantiza un acceso seguro. También puede aprovechar el Control de acceso basado en roles (RBAC) para definir permisos para usuarios y herramientas.\nAzure Container Instances (ACI)\nACI es una plataforma de implementación de contenedores sin servidor. Puede implementar aplicaciones contenedorizadas sin administrar la infraestructura subyacente. ACI admite contenedores tanto de Windows como de Linux y le permite especificar requisitos de recursos como CPU y memoria.\nPara el almacenamiento persistente, puede integrar Azure Files con ACI. ACI también ofrece políticas para definir el comportamiento de reinicio del contenedor en caso de fallas de la aplicación.\nConclusión clave\nLos contenedores ofrecen una forma poderosa y eficiente de empaquetar e implementar aplicaciones. Al aprovechar los servicios de Azure como ACR y ACI, los consultores cloud pueden optimizar el desarrollo y la implementación de aplicaciones contenedorizadas en la nube de Azure.\nRecuerde: Si bien esta publicación de blog se centra en los servicios de contenedores de Azure, los conceptos centrales de contenedores y Docker son aplicables a diferentes proveedores de nube.\n","date":"14 mayo 2023","externalUrl":null,"permalink":"/es/posts/202305-containers/","section":"Posts","summary":"Explorando contenedores en Azure","title":"Contenedores 101: Una guia general","type":"posts"},{"content":"","date":"10 febrero 2023","externalUrl":null,"permalink":"/es/tags/networking/","section":"Tags","summary":"","title":"Networking","type":"tags"},{"content":"En este artículo veremos en los servicios esenciales que hacen que tu red funcione: DNS, DHCP y proxies. Comprender estos servicios te permite administrar tu laboratorio doméstico con confianza y optimizar su rendimiento.\nDNS: La libreta de direcciones de Internet # Imagina el internet sin nombres de dominio como https://www.google.com/. El DNS (Sistema de Nombres de Dominio) actúa como la libreta de direcciones de internet, traduciendo nombres de dominio fáciles de usar en direcciones IP numéricas que los ordenadores entienden. Aquí hay un desglose de los componentes clave de DNS:\nServidores DNS: Estos son los caballos de batalla del DNS. Hay varios tipos:\nServidores de caché: Proporcionados por tu ISP o red local, almacenan búsquedas recientes para acelerar futuras solicitudes. Servidores recursivos: También de tu ISP o red local, realizan la resolución completa si la respuesta no está en la caché. Servidores raíz: La base de la jerarquía DNS, estos 13 servidores dirigen las solicitudes al servidor TLD apropiado. Servidores TLD: Administran dominios de nivel superior como \u0026ldquo;.com\u0026rdquo; o \u0026ldquo;.org\u0026rdquo; y dirigen las consultas al servidor de nombres autorizado. Servidores autorizados: La parada final, estos servidores contienen la dirección IP real para un dominio específico. Registros DNS: Estos son como entradas en la libreta de direcciones, que brindan diversos detalles sobre un dominio:\nRegistro A: Asigna un nombre de dominio a una dirección IPv4 (por ejemplo, \u0026ldquo; https://ipinfo.io/AS19527\u0026rdquo; -\u0026gt; 142.250.68.139) Registro AAAA: Similar al registro A, pero para direcciones IPv6. Registro CNAME: Redirige el tráfico de un dominio a otro (por ejemplo, \u0026ldquo; https://www.example.com\u0026rdquo; CNAME \u0026ldquo;example.com\u0026rdquo;) Registro MX: Dirige los correos electrónicos al servidor de correo correcto. Registro SRV: Define la ubicación de servicios específicos como chat o videoconferencia. Registro TXT: Almacena datos de texto adicionales para el dominio. Registro SOA: Especifica el servidor de nombres autorizado para una zona de dominio. Registro NS: Enumera otros servidores de nombres responsables de una zona. DHCP: Automatización de la configuración de red # ¿Estás cansado de asignar manualmente direcciones IP a cada dispositivo? DHCP (Protocolo de Configuración Dinámica de Host) viene al rescate. Automatiza la configuración de red para los dispositivos en tu red, asignando direcciones IP, máscaras de subred, puertas de enlace predeterminadas y servidores de nombres.\nProceso DHCP: Un dispositivo transmite un mensaje \u0026ldquo;DHCP Discover\u0026rdquo;. El servidor DHCP ofrece un arrendamiento (IP temporal) con un mensaje \u0026ldquo;DHCP Offer\u0026rdquo;. El dispositivo solicita el arrendamiento ofrecido con un mensaje \u0026ldquo;DHCP Request\u0026rdquo;. El servidor confirma con un mensaje \u0026ldquo;DHCP Ack\u0026rdquo;, finalizando la configuración. Los arrendamientos expiran, lo que requiere una renovación o una nueva negociación de arrendamiento. Proxies: Los intermediarios de la web # Un servidor proxy actúa como intermediario entre tu dispositivo e internet. Puede proporcionar diversas funcionalidades:\nSeguridad: Filtra contenido malicioso o protege la identidad de tu dispositivo. Caché: Almacena datos a los que se accede con frecuencia para acelerar la navegación. Filtrado de contenido: Restringe el acceso a determinados sitios web. Balanceo de carga: Distribuye el tráfico entre varios servidores para un mejor rendimiento. Conclusión # Comprender DNS, DHCP y proxies te permite administrar la red de tu laboratorio doméstico de manera eficaz. Puedes optimizar el rendimiento, mejorar la seguridad y obtener un control granular sobre cómo se conectan tus dispositivos a internet. ¡Con este conocimiento, tu laboratorio doméstico puede convertirse en una poderosa plataforma para la experimentación y el aprendizaje!\n","date":"10 febrero 2023","externalUrl":null,"permalink":"/es/posts/202302-basicnetworking/","section":"Posts","summary":"Explorando conceptos basicos de redes para un homelab","title":"Redes 101: DNS, DHCP, y Proxies","type":"posts"},{"content":"","date":"1 enero 0001","externalUrl":null,"permalink":"/es/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","date":"1 enero 0001","externalUrl":null,"permalink":"/es/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":" Experiencia Compañia Link Rol Fechas Ubicación Thomson Reuters Ingeniero DevOps Senior 2023 - Present CDMX, Mexico Honeywell Ingeniero de Software 2021 - 2023 CDMX, Mexico Educación Escuela Link Grado Fechas Ubicación Instituto Politécnico Nacional Ingenieria en Control y Automatización 2017-2022 CDMX, Mexico ","date":"1 enero 0001","externalUrl":null,"permalink":"/es/resume/","section":"Alberto Olvera","summary":" Experiencia Compañia Link Rol Fechas Ubicación Thomson Reuters Ingeniero DevOps Senior 2023 - Present CDMX, Mexico Honeywell Ingeniero de Software 2021 - 2023 CDMX, Mexico Educación Escuela Link Grado Fechas Ubicación Instituto Politécnico Nacional Ingenieria en Control y Automatización 2017-2022 CDMX, Mexico ","title":"Curriculum","type":"page"},{"content":"Hola, este es mi espacio para compartir mis conocimientos y explorar todo lo relacionado con la tecnología, especialmente el mundo de la infraestructura, la computación en la nube y el panorama en constante evolución de DevOps. Soy un apasionado ingeniero DevOps con algunos años de experiencia, pero mi curiosidad me mantiene en diferentes áreas - desarrollo backend, frontend, e incluso la administración de la nube.\nYa sea abordando proyectos de infraestructura o profundizando en las últimas tendencias de DevOps, disfruto del proceso de aprender y crear. Este blog es mi forma de compartir ese viaje contigo.\nGracias por acompañarme.\nEsto es lo que puedes esperar\nAbordaré temas técnicos relacionados con la infraestructura, la nube y DevOps, proporcionando explicaciones perspicaces y consejos prácticos. Aprende de mis aventuras mientras navego por el siempre cambiante panorama tecnológico. No importa tu formación tecnológica, aquí hay algo para todos. Aprendamos y crezcamos juntos.\nP.D. ¡No dudes en ponerte en contacto conmigo!\n","date":"1 enero 0001","externalUrl":null,"permalink":"/es/about/","section":"Alberto Olvera","summary":"Hola, este es mi espacio para compartir mis conocimientos y explorar todo lo relacionado con la tecnología, especialmente el mundo de la infraestructura, la computación en la nube y el panorama en constante evolución de DevOps.","title":"Sobre mi","type":"page"}]